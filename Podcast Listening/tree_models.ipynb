{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(\"data/data/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "train = train_df.filter(pl.col(\"Episode_Length_minutes\").is_not_null()).to_pandas()\n",
    "test  = train_df.filter(pl.col(\"Episode_Length_minutes\").is_null()).to_pandas()\n",
    "\n",
    "features = [\"Host_Popularity_percentage\", \"Guest_Popularity_percentage\", \"Number_of_Ads\"]\n",
    "X_train = train[features]\n",
    "y_train = train[\"Episode_Length_minutes\"]\n",
    "X_test  = test[features]\n",
    "\n",
    "# fit & predict\n",
    "rf_impute = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_impute.fit(X_train, y_train)\n",
    "preds = rf_impute.predict(X_test)\n",
    "\n",
    "test[\"Episode_Length_imp\"] = preds\n",
    "train[\"Episode_Length_imp\"] = train[\"Episode_Length_minutes\"]\n",
    "\n",
    "# combine\n",
    "import pandas as pd\n",
    "combined = pd.concat([train, test], sort=False)\n",
    "df = pl.from_pandas(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "df = df.with_columns([\n",
    "  # ad & popularity\n",
    "  (pl.col(\"Number_of_Ads\")/pl.col(\"Episode_Length_imp\")).alias(\"ad_density\"),\n",
    "  (pl.col(\"Host_Popularity_percentage\") - pl.col(\"Guest_Popularity_percentage\").fill_null(0)).alias(\"pop_gap\"),\n",
    "  ((pl.col(\"Host_Popularity_percentage\")+pl.col(\"Guest_Popularity_percentage\").fill_null(0))/2).alias(\"pop_avg\"),\n",
    "  pl.col(\"Guest_Popularity_percentage\").is_not_null().cast(pl.Int8).alias(\"has_guest\"),\n",
    "\n",
    "  # title parsing\n",
    "  pl.col(\"Episode_Title\").str.extract(r\"(\\d+)\").cast(pl.Int64).alias(\"Episode_Number\"),\n",
    "  pl.col(\"Episode_Title\").str.len_chars().alias(\"Title_Char_Count\"),\n",
    "  pl.col(\"Episode_Title\").str.split(\" \").list.len().alias(\"Title_Word_Count\"),\n",
    "\n",
    "  # temporal\n",
    "  pl.when(pl.col(\"Publication_Day\").is_in([\"Saturday\",\"Sunday\"])).then(1).otherwise(0).alias(\"is_weekend\"),\n",
    "  pl.col(\"Publication_Day\").map_elements(lambda d: [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"].index(d)+1).alias(\"day_of_week_num\"),\n",
    "  pl.col(\"Publication_Time\").map_elements(lambda t: {\"Morning\":1,\"Afternoon\":2,\"Evening\":3,\"Night\":4}[t]).alias(\"time_of_day_num\"),\n",
    "\n",
    "  # sentiment\n",
    "  pl.when(pl.col(\"Episode_Sentiment\")==\"Positive\").then(1)\n",
    "    .when(pl.col(\"Episode_Sentiment\")==\"Neutral\").then(0)\n",
    "    .when(pl.col(\"Episode_Sentiment\")==\"Negative\").then(-1)\n",
    "    .alias(\"sentiment_num\"),\n",
    "\n",
    "  # transforms & interactions\n",
    "  pl.col(\"Episode_Length_imp\").log1p().alias(\"log_length\"),\n",
    "  pl.col(\"Number_of_Ads\").log1p().alias(\"log_ads\"),\n",
    "  (pl.col(\"Episode_Length_imp\") * pl.col(\"Number_of_Ads\")).alias(\"length_x_ads\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (750_000, 27)\n",
      "┌────────┬────────────┬────────────┬────────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
      "│ id     ┆ Podcast_Na ┆ Episode_Ti ┆ Episode_Le ┆ … ┆ sentiment ┆ log_lengt ┆ log_ads  ┆ length_x_ │\n",
      "│ ---    ┆ me         ┆ tle        ┆ ngth_minut ┆   ┆ _num      ┆ h         ┆ ---      ┆ ads       │\n",
      "│ i64    ┆ ---        ┆ ---        ┆ es         ┆   ┆ ---       ┆ ---       ┆ f64      ┆ ---       │\n",
      "│        ┆ str        ┆ str        ┆ ---        ┆   ┆ i32       ┆ f64       ┆          ┆ f64       │\n",
      "│        ┆            ┆            ┆ f64        ┆   ┆           ┆           ┆          ┆           │\n",
      "╞════════╪════════════╪════════════╪════════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
      "│ 1      ┆ Joke       ┆ Episode 26 ┆ 119.8      ┆ … ┆ -1        ┆ 4.794136  ┆ 1.098612 ┆ 239.6     │\n",
      "│        ┆ Junction   ┆            ┆            ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 2      ┆ Study      ┆ Episode 16 ┆ 73.9       ┆ … ┆ -1        ┆ 4.316154  ┆ 0.0      ┆ 0.0       │\n",
      "│        ┆ Sessions   ┆            ┆            ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 3      ┆ Digital    ┆ Episode 45 ┆ 67.17      ┆ … ┆ 1         ┆ 4.222005  ┆ 1.098612 ┆ 134.34    │\n",
      "│        ┆ Digest     ┆            ┆            ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 4      ┆ Mind &     ┆ Episode 86 ┆ 110.51     ┆ … ┆ 0         ┆ 4.714114  ┆ 1.386294 ┆ 331.53    │\n",
      "│        ┆ Body       ┆            ┆            ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 5      ┆ Fitness    ┆ Episode 19 ┆ 26.54      ┆ … ┆ 1         ┆ 3.315639  ┆ 1.386294 ┆ 79.62     │\n",
      "│        ┆ First      ┆            ┆            ┆   ┆           ┆           ┆          ┆           │\n",
      "│ …      ┆ …          ┆ …          ┆ …          ┆ … ┆ …         ┆ …         ┆ …        ┆ …         │\n",
      "│ 749926 ┆ Current    ┆ Episode 48 ┆ null       ┆ … ┆ 1         ┆ 3.791874  ┆ 1.386294 ┆ 130.0182  │\n",
      "│        ┆ Affairs    ┆            ┆            ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 749936 ┆ Melody Mix ┆ Episode 7  ┆ null       ┆ … ┆ -1        ┆ 4.128484  ┆ 0.0      ┆ 0.0       │\n",
      "│ 749943 ┆ World      ┆ Episode 42 ┆ null       ┆ … ┆ 0         ┆ 4.234698  ┆ 0.693147 ┆ 68.0408   │\n",
      "│        ┆ Watch      ┆            ┆            ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 749954 ┆ Life       ┆ Episode 54 ┆ null       ┆ … ┆ 0         ┆ 4.184158  ┆ 1.098612 ┆ 129.2764  │\n",
      "│        ┆ Lessons    ┆            ┆            ┆   ┆           ┆           ┆          ┆           │\n",
      "│ 749984 ┆ Game Day   ┆ Episode 13 ┆ null       ┆ … ┆ 1         ┆ 3.66012   ┆ 0.693147 ┆ 37.866    │\n",
      "└────────┴────────────┴────────────┴────────────┴───┴───────────┴───────────┴──────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    # original numerics\n",
    "    \"Episode_Length_imp\", \"Host_Popularity_percentage\", \"Guest_Popularity_percentage\",\n",
    "    \"Number_of_Ads\",\n",
    "    # engineered\n",
    "    \"ad_density\", \"pop_gap\", \"pop_avg\", \"has_guest\",\n",
    "    \"Episode_Number\", \"Title_Char_Count\", \"Title_Word_Count\",\n",
    "    \"is_weekend\", \"day_of_week_num\", \"time_of_day_num\",\n",
    "    \"sentiment_num\", \"log_length\", \"log_ads\", \"length_x_ads\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.select(feature_cols).to_numpy()\n",
    "y = df.select(\"Listening_Time_minutes\").to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree    RMSE (all): 8.49   —  RMSE (test): 18.90\n",
      "Random Forest    RMSE (all): 7.39   —  RMSE (test): 13.18\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 4a) Decision Tree\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred_dt_all  = dt.predict(X)        # in‑sample\n",
    "y_pred_dt_test = dt.predict(X_test)   # hold‑out\n",
    "\n",
    "# RMSE\n",
    "mse_dt_all  = mean_squared_error(y, y_pred_dt_all)\n",
    "mse_dt_test = mean_squared_error(y_test, y_pred_dt_test)\n",
    "\n",
    "\n",
    "# 4b) Random Forest\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100, random_state=42, n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf_all  = rf.predict(X)\n",
    "y_pred_rf_test = rf.predict(X_test)\n",
    "\n",
    "rmse_rf_all  = mean_squared_error(y, y_pred_rf_all)\n",
    "rmse_rf_test = mean_squared_error(y_test, y_pred_rf_test)\n",
    "\n",
    "# 5) Report\n",
    "print(f\"Decision Tree    RMSE (all): {np.sqrt(mse_dt_all):.2f}   —  RMSE (test): {np.sqrt(mse_dt_test):.2f}\")\n",
    "print(f\"Random Forest    RMSE (all): {np.sqrt(rmse_rf_all):.2f}   —  RMSE (test): {np.sqrt(rmse_rf_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE (all):  13.36\n",
      "XGBoost RMSE (test): 13.37\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "# 4) Fit\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# 5) Predictions\n",
    "y_pred_all  = xgb.predict(X)        # in‑sample\n",
    "y_pred_test = xgb.predict(X_test)   # hold‑out\n",
    "\n",
    "# 6) Compute RMSE\n",
    "rmse_all  = mean_squared_error(y, y_pred_all)\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"XGBoost RMSE (all):  {np.sqrt(rmse_all):.2f}\")\n",
    "print(f\"XGBoost RMSE (test): {np.sqrt(rmse_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST DF TIMEEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pl.read_csv(\"data/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = test_df.filter(pl.col(\"Episode_Length_minutes\").is_not_null()).to_pandas()\n",
    "test  = test_df.filter(pl.col(\"Episode_Length_minutes\").is_null()).to_pandas()\n",
    "\n",
    "features = [\"Host_Popularity_percentage\", \"Guest_Popularity_percentage\", \"Number_of_Ads\"]\n",
    "X_test  = test[features]\n",
    "\n",
    "preds = rf_impute.predict(X_test)\n",
    "\n",
    "test[\"Episode_Length_imp\"] = preds\n",
    "train[\"Episode_Length_imp\"] = train[\"Episode_Length_minutes\"]\n",
    "\n",
    "# combine\n",
    "import pandas as pd\n",
    "combined = pd.concat([train, test], sort=False)\n",
    "df = pl.from_pandas(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "df = df.with_columns([\n",
    "  # ad & popularity\n",
    "  (pl.col(\"Number_of_Ads\")/pl.col(\"Episode_Length_imp\")).alias(\"ad_density\"),\n",
    "  (pl.col(\"Host_Popularity_percentage\") - pl.col(\"Guest_Popularity_percentage\").fill_null(0)).alias(\"pop_gap\"),\n",
    "  ((pl.col(\"Host_Popularity_percentage\")+pl.col(\"Guest_Popularity_percentage\").fill_null(0))/2).alias(\"pop_avg\"),\n",
    "  pl.col(\"Guest_Popularity_percentage\").is_not_null().cast(pl.Int8).alias(\"has_guest\"),\n",
    "\n",
    "  # title parsing\n",
    "  pl.col(\"Episode_Title\").str.extract(r\"(\\d+)\").cast(pl.Int64).alias(\"Episode_Number\"),\n",
    "  pl.col(\"Episode_Title\").str.len_chars().alias(\"Title_Char_Count\"),\n",
    "  pl.col(\"Episode_Title\").str.split(\" \").list.len().alias(\"Title_Word_Count\"),\n",
    "\n",
    "  # temporal\n",
    "  pl.when(pl.col(\"Publication_Day\").is_in([\"Saturday\",\"Sunday\"])).then(1).otherwise(0).alias(\"is_weekend\"),\n",
    "  pl.col(\"Publication_Day\").map_elements(lambda d: [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"].index(d)+1).alias(\"day_of_week_num\"),\n",
    "  pl.col(\"Publication_Time\").map_elements(lambda t: {\"Morning\":1,\"Afternoon\":2,\"Evening\":3,\"Night\":4}[t]).alias(\"time_of_day_num\"),\n",
    "\n",
    "  # sentiment\n",
    "  pl.when(pl.col(\"Episode_Sentiment\")==\"Positive\").then(1)\n",
    "    .when(pl.col(\"Episode_Sentiment\")==\"Neutral\").then(0)\n",
    "    .when(pl.col(\"Episode_Sentiment\")==\"Negative\").then(-1)\n",
    "    .alias(\"sentiment_num\"),\n",
    "\n",
    "  # transforms & interactions\n",
    "  pl.col(\"Episode_Length_imp\").log1p().alias(\"log_length\"),\n",
    "  pl.col(\"Number_of_Ads\").log1p().alias(\"log_ads\"),\n",
    "  (pl.col(\"Episode_Length_imp\") * pl.col(\"Number_of_Ads\")).alias(\"length_x_ads\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to submissions/random_forest.csv\n",
      "Number of predictions: 250000\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for prediction\n",
    "feature_cols = [\n",
    "    # original numerics\n",
    "    \"Episode_Length_imp\", \"Host_Popularity_percentage\", \"Guest_Popularity_percentage\",\n",
    "    \"Number_of_Ads\",\n",
    "    # engineered\n",
    "    \"ad_density\", \"pop_gap\", \"pop_avg\", \"has_guest\",\n",
    "    \"Episode_Number\", \"Title_Char_Count\", \"Title_Word_Count\",\n",
    "    \"is_weekend\", \"day_of_week_num\", \"time_of_day_num\",\n",
    "    \"sentiment_num\", \"log_length\", \"log_ads\", \"length_x_ads\",\n",
    "]\n",
    "\n",
    "# Extract features for prediction\n",
    "X_test_pred = df[feature_cols]\n",
    "\n",
    "# Make predictions using the random forest model\n",
    "predictions = rf.predict(X_test_pred)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Listening_Time_minutes': predictions\n",
    "})\n",
    "\n",
    "# Ensure directory exists\n",
    "import os\n",
    "os.makedirs('submissions', exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submissions/random_forest.csv', index=False)\n",
    "\n",
    "print(f\"Predictions saved to submissions/random_forest.csv\")\n",
    "print(f\"Number of predictions: {len(predictions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to submissions/xgb.csv\n",
      "Number of predictions: 250000\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for prediction\n",
    "feature_cols = [\n",
    "    # original numerics\n",
    "    \"Episode_Length_imp\", \"Host_Popularity_percentage\", \"Guest_Popularity_percentage\",\n",
    "    \"Number_of_Ads\",\n",
    "    # engineered\n",
    "    \"ad_density\", \"pop_gap\", \"pop_avg\", \"has_guest\",\n",
    "    \"Episode_Number\", \"Title_Char_Count\", \"Title_Word_Count\",\n",
    "    \"is_weekend\", \"day_of_week_num\", \"time_of_day_num\",\n",
    "    \"sentiment_num\", \"log_length\", \"log_ads\", \"length_x_ads\",\n",
    "]\n",
    "\n",
    "# Extract features for prediction\n",
    "X_test_pred = df[feature_cols]\n",
    "\n",
    "# Make predictions using the random forest model\n",
    "predictions = xgb.predict(X_test_pred)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Listening_Time_minutes': predictions\n",
    "})\n",
    "\n",
    "# Ensure directory exists\n",
    "import os\n",
    "os.makedirs('submissions', exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submissions/xgb.csv', index=False)\n",
    "\n",
    "print(f\"Predictions saved to submissions/xgb.csv\")\n",
    "print(f\"Number of predictions: {len(predictions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
